{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Batch processing the data was giving me a lot of trouble on the labels end, so switching it to a batch size of 1 and changing the weight of the max pooling layer fixes that and lets the model run all the way through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/train/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300\n",
      "5300\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import sklearn.model_selection as sk\n",
    "\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# # Import MNIST data\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "\n",
    "feats = np.loadtxt('features_filtered.txt', dtype='float32')[0:5300]\n",
    "labels = np.loadtxt('onehot-labels_filtered.txt')[0:5300]\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_steps = 3000\n",
    "batch_size = 1\n",
    "display_step = 10\n",
    "\n",
    "#features_len = 81#len(feats[0]) #number of potential features provided, some rarely used\n",
    "\n",
    "num_input = 81#features_len\n",
    "num_classes = len(labels[0])\n",
    "dropout = 0.25 #tuneable\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "\n",
    "# tf Graph input\n",
    "print(len(feats))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-1eef18625ede>:62: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    # MaxPool2D wrapper\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    try:\n",
    "        x = tf.reshape(x, shape=[-1, 9, 9, 1])\n",
    "    # Convolution Layer\n",
    "        conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling)\n",
    "        conv1 = maxpool2d(conv1, k=2)\n",
    "    # Convolution Layer\n",
    "        conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling)\n",
    "        conv2 = maxpool2d(conv2, k=2)\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "        fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "        fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "        fc1 = tf.nn.relu(fc1)\n",
    "        # Apply Dropout\n",
    "        fc1 = tf.nn.dropout(fc1, dropout)\n",
    "        # Output, class prediction\n",
    "        out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "        return out    \n",
    "    except Exception as e:\n",
    "        return e\n",
    "    \n",
    "weights = {\n",
    "    # 5x5 conv, 1 input, 32 outputs\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 conv, 32 inputs, 64 outputs\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
    "    'wd1': tf.Variable(tf.random_normal([batch_size*3*3*64, 1024])),\n",
    "    # 1024 inputs, 10 outputs (class prediction)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}\n",
    "\n",
    "# Construct model\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "Step 0, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 10, Minibatch Loss= 5121894.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 20, Minibatch Loss= 13478917.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 30, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 40, Minibatch Loss= 4731365.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 50, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 60, Minibatch Loss= 3001183.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 70, Minibatch Loss= 539053.0625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 80, Minibatch Loss= 5080553.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 90, Minibatch Loss= 887984.9375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 110, Minibatch Loss= 2464622.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 140, Minibatch Loss= 2347524.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 170, Minibatch Loss= 9780589.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 190, Minibatch Loss= 1378226.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 220, Minibatch Loss= 217889.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 250, Minibatch Loss= 24729978.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 270, Minibatch Loss= 3134892.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 290, Minibatch Loss= 3003335.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 300, Minibatch Loss= 10217496.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 320, Minibatch Loss= 96665.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 370, Minibatch Loss= 914298.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 380, Minibatch Loss= 457256.0312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 390, Minibatch Loss= 803735.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 410, Minibatch Loss= 1145886.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 420, Minibatch Loss= 347212.0312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 440, Minibatch Loss= 953748.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 500, Minibatch Loss= 10072702.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 520, Minibatch Loss= 229825.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 530, Minibatch Loss= 3436679.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 550, Minibatch Loss= 2102066.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 560, Minibatch Loss= 2143019.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 570, Minibatch Loss= 1719796.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 580, Minibatch Loss= 2848308.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 600, Minibatch Loss= 1020429.4375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 610, Minibatch Loss= 602699.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 620, Minibatch Loss= 135281.7344, Training Accuracy= 0.000\n",
      "x\n",
      "Step 630, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 640, Minibatch Loss= 37095.5781, Training Accuracy= 0.000\n",
      "x\n",
      "Step 650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 670, Minibatch Loss= 298372.0312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 680, Minibatch Loss= 1435239.8750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 710, Minibatch Loss= 2251764.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 730, Minibatch Loss= 1349908.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 750, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 760, Minibatch Loss= 3536604.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 810, Minibatch Loss= 483127.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 840, Minibatch Loss= 253028.0312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 870, Minibatch Loss= 416791.0625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 880, Minibatch Loss= 239747.2656, Training Accuracy= 0.000\n",
      "x\n",
      "Step 890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 920, Minibatch Loss= 61685.0625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 930, Minibatch Loss= 5766431.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 940, Minibatch Loss= 23373.6035, Training Accuracy= 0.000\n",
      "x\n",
      "Step 950, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 980, Minibatch Loss= 3285202.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1010, Minibatch Loss= 127129104.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1020, Minibatch Loss= 7204751.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1040, Minibatch Loss= 2569076.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1050, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1060, Minibatch Loss= 7289385.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1070, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1080, Minibatch Loss= 927028.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1090, Minibatch Loss= 3049648.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1110, Minibatch Loss= 2252385.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1120, Minibatch Loss= 4156520.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1140, Minibatch Loss= 622174.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1170, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1190, Minibatch Loss= 1757981.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1230, Minibatch Loss= 125044.7578, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1250, Minibatch Loss= 84534.5312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1260, Minibatch Loss= 2131634.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1270, Minibatch Loss= 558781.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1280, Minibatch Loss= 842587.0000, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "Step 1290, Minibatch Loss= 523105.4688, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1330, Minibatch Loss= 1221867.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1340, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1380, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1400, Minibatch Loss= 170553.7812, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1410, Minibatch Loss= 31793.8203, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1430, Minibatch Loss= 1905058.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1480, Minibatch Loss= 691667.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1500, Minibatch Loss= 81453608.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1520, Minibatch Loss= 852873.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1550, Minibatch Loss= 251854.5938, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1560, Minibatch Loss= 1132104.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1570, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1580, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1600, Minibatch Loss= 20199.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1630, Minibatch Loss= 346347.3750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1640, Minibatch Loss= 866585.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1650, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1660, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1670, Minibatch Loss= 790327.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1690, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1710, Minibatch Loss= 762904.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1730, Minibatch Loss= 1026281.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1740, Minibatch Loss= 3834879.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1750, Minibatch Loss= 381393.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1760, Minibatch Loss= 78571.1250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1770, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1790, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1800, Minibatch Loss= 800722.1250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1810, Minibatch Loss= 621351.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1840, Minibatch Loss= 175213.9375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1860, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1870, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1920, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1930, Minibatch Loss= 326528.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1940, Minibatch Loss= 3751047.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1950, Minibatch Loss= 99942.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 1960, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1970, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 1990, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2000, Minibatch Loss= 117187.5625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2010, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2020, Minibatch Loss= 607574.1250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2040, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2050, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2060, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2070, Minibatch Loss= 702044.4375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2080, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2090, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2100, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2110, Minibatch Loss= 2094218.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2130, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2140, Minibatch Loss= 1290911.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2150, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2170, Minibatch Loss= 285587.8438, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2180, Minibatch Loss= 1437019.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2190, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2200, Minibatch Loss= 525540.1875, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2230, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2240, Minibatch Loss= 2304027.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2250, Minibatch Loss= 2547305.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2270, Minibatch Loss= 15683694.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2280, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2300, Minibatch Loss= 5870217.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2320, Minibatch Loss= 218366.4219, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2330, Minibatch Loss= 98080.0469, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2340, Minibatch Loss= 1145907.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2350, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2360, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2380, Minibatch Loss= 1325150.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2400, Minibatch Loss= 68552.5156, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2420, Minibatch Loss= 1094305.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2430, Minibatch Loss= 194483.3750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2440, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2450, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2460, Minibatch Loss= 882681.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2470, Minibatch Loss= 359722.4375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2480, Minibatch Loss= 265919.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2530, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2560, Minibatch Loss= 404768.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2570, Minibatch Loss= 1048932.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2580, Minibatch Loss= 2046495.0000, Training Accuracy= 0.000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      "Step 2590, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2600, Minibatch Loss= 1171475.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2610, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2620, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2630, Minibatch Loss= 55865032.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2640, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2650, Minibatch Loss= 325818.8750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2660, Minibatch Loss= 163068.5625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2670, Minibatch Loss= 2162940.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2680, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2690, Minibatch Loss= 136723.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2700, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2710, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2720, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2730, Minibatch Loss= 514666.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2740, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2750, Minibatch Loss= 1463039.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2760, Minibatch Loss= 153893.8125, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2770, Minibatch Loss= 26852.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2780, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2790, Minibatch Loss= 321960.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2800, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2810, Minibatch Loss= 328815.3750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2820, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2830, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2840, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2850, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2860, Minibatch Loss= 2098246.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2870, Minibatch Loss= 755479.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2880, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2890, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2900, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2910, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2920, Minibatch Loss= 1647778.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2930, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2940, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2950, Minibatch Loss= 700378.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2960, Minibatch Loss= 145126.6562, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2970, Minibatch Loss= 95230.3125, Training Accuracy= 0.000\n",
      "x\n",
      "Step 2980, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 2990, Minibatch Loss= 2714360.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3010, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3020, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3030, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3040, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3050, Minibatch Loss= 792211.1250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3060, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3070, Minibatch Loss= 279232.3438, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3080, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3090, Minibatch Loss= 362046.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3100, Minibatch Loss= 329565.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3110, Minibatch Loss= 195924.2500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3120, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3130, Minibatch Loss= 350553.8750, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3140, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3150, Minibatch Loss= 586321.5625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3160, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3170, Minibatch Loss= 1430441.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3180, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3190, Minibatch Loss= 560917.9375, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3200, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3210, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3220, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3230, Minibatch Loss= 1326203.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3240, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3250, Minibatch Loss= 166759.0625, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3260, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3270, Minibatch Loss= 6278.0107, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3280, Minibatch Loss= 2415584.0000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3290, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3310, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3320, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3330, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3340, Minibatch Loss= 1788599.5000, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3350, Minibatch Loss= 152338.4219, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3360, Minibatch Loss= 202960.7500, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3370, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3380, Minibatch Loss= 43668.2188, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3390, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3400, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3410, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3420, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3430, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3440, Minibatch Loss= 211711.0312, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3450, Minibatch Loss= 1066709.6250, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3460, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3470, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3480, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3490, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3500, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3510, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3520, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3530, Minibatch Loss= 849001.8125, Training Accuracy= 0.000\n",
      "x\n",
      "Step 3540, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "x\n",
      "Step 3550, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
      "Optimization Finished!\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "X_train, X_test, y_train, y_test = sk.train_test_split(feats,labels,test_size=0.33,random_state=5)\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for c in range(0,len(X_train), batch_size):\n",
    "        batch_x = X_train[c:c+batch_size]\n",
    "        batch_y = y_train[c:c+batch_size]\n",
    "        #sess.run(logits, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        #sess.run(optimizer, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        #sess.run(loss_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout}) ##train_op not compiling for some reason, need to investigate why\n",
    "        if c % display_step == 0 or c == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            print('x')\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0})\n",
    "            print(\"Step \" + str(c) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"Optimization Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
